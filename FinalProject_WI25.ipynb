{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)\n",
    "\n",
    "# Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [ X ] YES - make available\n",
    "* [  ] NO - keep private\n",
    "\n",
    "# Name\n",
    "\n",
    "- Kaylie Mendoza\n",
    "\n",
    "# Abstract\n",
    "\n",
    "Please write one to four paragraphs that describe a very brief overview of why you did this, how you did, and the major findings and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    "  **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Arenâ€™t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name: congress-legislators/executive.yaml\n",
    "  - Link to the dataset: https://github.com/unitedstates/congress-legislators/blob/main/executive.yaml\n",
    "  - Number of observations: 80\n",
    "  - Number of variables: 4\n",
    "\n",
    "The `executive.yaml` dataset contains 80 observations and 4 variables, providing information about U.S. presidents and vice presidents. Key variables include `name` (details about the individual's name), `bio` (biographical details such as birthdate and gender), and `terms` (a list of terms served, including start and end dates, party affiliation, and how they assumed office). The dataset is in a nested YAML format, requiring preprocessing to flatten the structure into a tabular format. This preprocessing involved parsing nested fields, expanding term records, and calculating additional metrics such as term durations, ages, and zodiac signs for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U.S. Presidents and Vice Presidents Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Data parsing\n",
    "import yaml\n",
    "import ast\n",
    "\n",
    "# Date calculations\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'congress-legislators/executive.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m executive_csv = \u001b[33m'\u001b[39m\u001b[33mexecutive.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load YAML and convert to DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutive_yaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      9\u001b[39m     df = pd.DataFrame(yaml.safe_load(f))\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/COGS108_Final_Project/myenv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'congress-legislators/executive.yaml'"
     ]
    }
   ],
   "source": [
    "# Initial Data Loading and YAML to CSV Conversion\n",
    "\n",
    "# Set up input and output paths\n",
    "executive_yaml = 'congress-legislators/executive.yaml'\n",
    "executive_csv = 'executive.csv'\n",
    "\n",
    "# Load YAML and convert to DataFrame\n",
    "with open(executive_yaml, 'r') as f:\n",
    "    df = pd.DataFrame(yaml.safe_load(f))\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(executive_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the U.S. Presidents and Vice Presidents Dataset\n",
    "executive = pd.read_csv('executive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the executive DataFrame\n",
    "\n",
    "# 1. Extract name fields\n",
    "names = pd.json_normalize(executive['name'].apply(eval))\n",
    "\n",
    "# 2. Extract bio fields\n",
    "bios = pd.json_normalize(executive['bio'].apply(eval))\n",
    "bios = bios[['birthday', 'gender']]\n",
    "\n",
    "# 3. Expand terms\n",
    "def expand_term(row):\n",
    "    terms = eval(row['terms'])\n",
    "    expanded = pd.json_normalize(terms)\n",
    "    expanded = expanded[['type', 'party', 'start', 'end', 'how']]\n",
    "    \n",
    "    # Add name and bio information\n",
    "    for col in names.columns:\n",
    "        expanded[col] = names.loc[row.name, col]\n",
    "    for col in bios.columns:\n",
    "        expanded[col] = bios.loc[row.name, col]\n",
    "    \n",
    "    return expanded\n",
    "\n",
    "# Process each row's 'terms' column data into a single DataFrame\n",
    "expanded_terms = [expand_term(row) for _, row in executive.iterrows()]\n",
    "executive = pd.concat(expanded_terms, ignore_index=True)\n",
    "\n",
    "# Remove duplicate columns and original nested data columns\n",
    "columns_to_drop = ['id', 'name', 'bio', 'terms']\n",
    "executive = executive.loc[:, ~executive.columns.duplicated()]\n",
    "executive = executive.drop(columns=[col for col in columns_to_drop if col in executive.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date strings to datetime.date objects\n",
    "\n",
    "date_columns = {\n",
    "    'birthday': 'birthdate',\n",
    "    'start': 'start_term',\n",
    "    'end': 'end_term'\n",
    "}\n",
    "\n",
    "for old_col, new_col in date_columns.items():\n",
    "    executive[new_col] = pd.to_datetime(executive[old_col], errors='coerce').dt.date\n",
    "    executive = executive.drop(columns=[old_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full names by combining name components\n",
    "executive['full_name'] = executive.apply(\n",
    "    lambda row: ' '.join(filter(pd.notnull, [\n",
    "        row['first'],\n",
    "        f'\"{row[\"nickname\"]}\"' if pd.notnull(row['nickname']) else None,\n",
    "        row['middle'],\n",
    "        row['last'],\n",
    "        row['suffix']\n",
    "    ])) or None,\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'birthday' column from the 'birthdate' column by extracting month-day\n",
    "executive['birthday'] = executive['birthdate'].apply(lambda x: x.strftime('%m-%d') if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define zodiac signs and their date ranges\n",
    "zodiac_ranges = [\n",
    "    (\"Capricorn\", [(12, 22, 12, 31), (1, 1, 1, 19)]),\n",
    "    (\"Aquarius\", [(1, 20, 2, 18)]),\n",
    "    (\"Pisces\", [(2, 19, 3, 20)]),\n",
    "    (\"Aries\", [(3, 21, 4, 19)]),\n",
    "    (\"Taurus\", [(4, 20, 5, 20)]),\n",
    "    (\"Gemini\", [(5, 21, 6, 20)]),\n",
    "    (\"Cancer\", [(6, 21, 7, 22)]),\n",
    "    (\"Leo\", [(7, 23, 8, 22)]),\n",
    "    (\"Virgo\", [(8, 23, 9, 22)]),\n",
    "    (\"Libra\", [(9, 23, 10, 22)]),\n",
    "    (\"Scorpio\", [(10, 23, 11, 21)]),\n",
    "    (\"Sagittarius\", [(11, 22, 12, 21)])\n",
    "]\n",
    "\n",
    "# Get zodiac sign from birthday\n",
    "def in_date_range(month, day, range_tuple):\n",
    "    if len(range_tuple) == 4:  # Single range\n",
    "        start_m, start_d, end_m, end_d = range_tuple\n",
    "        return (month, day) >= (start_m, start_d) and (month, day) <= (end_m, end_d)\n",
    "    else:  # Split range (for Capricorn)\n",
    "        return any(in_date_range(month, day, r) for r in range_tuple)\n",
    "\n",
    "executive['zodiac_sign'] = executive['birthday'].apply(\n",
    "    lambda x: next(\n",
    "        (sign for sign, ranges in zodiac_ranges \n",
    "         if x and any(in_date_range(*map(int, x.split('-')), r) for r in ranges)),\n",
    "        None\n",
    "    ) if x else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zodiac sign color mapping\n",
    "# this dictionary maps each zodiac sign to a specific color (hex code).\n",
    "# colors are chosen to represent traits commonly associated with each sign.\n",
    "\n",
    "zodiac_colors = {\n",
    "    'Aries': '#FF0000',       # red for Aries (bold and energetic)\n",
    "    'Taurus': '#008000',      # green for Taurus (grounded and earthy)\n",
    "    'Gemini': '#FFFF00',      # yellow for Gemini (bright and lively)\n",
    "    'Cancer': '#00008B',      # dark blue for Cancer (deep and emotional)\n",
    "    'Leo': '#FFA500',         # orange for Leo (warm and vibrant)\n",
    "    'Virgo': '#A52A2A',       # brown for Virgo (practical and grounded)\n",
    "    'Libra': '#FFB6C1',       # light pink for Libra (harmonious and gentle)\n",
    "    'Scorpio': '#000000',     # black for Scorpio (mysterious and intense)\n",
    "    'Sagittarius': '#800080', # purple for Sagittarius (adventurous and wise)\n",
    "    'Capricorn': '#556B2F',   # olive green for Capricorn (disciplined and stable)\n",
    "    'Aquarius': '#0000FF',    # blue for Aquarius (innovative and free-spirited)\n",
    "    'Pisces': '#40E0D0',      # turquoise for Pisces (dreamy and intuitive)\n",
    "    'Unknown': '#D3D3D3'      # light gray for unknown or missing zodiac signs\n",
    "}\n",
    "\n",
    "# Add a new column for zodiac colors\n",
    "executive['zodiac_color'] = executive['zodiac_sign'].map(lambda x: zodiac_colors.get(x, zodiac_colors['Unknown']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zodiac elements mapping\n",
    "zodiac_elements = {\n",
    "    'Aries': 'Fire',\n",
    "    'Taurus': 'Earth',\n",
    "    'Gemini': 'Air',\n",
    "    'Cancer': 'Water',\n",
    "    'Leo': 'Fire',\n",
    "    'Virgo': 'Earth',\n",
    "    'Libra': 'Air',\n",
    "    'Scorpio': 'Water',\n",
    "    'Sagittarius': 'Fire',\n",
    "    'Capricorn': 'Earth',\n",
    "    'Aquarius': 'Air',\n",
    "    'Pisces': 'Water'\n",
    "}\n",
    "\n",
    "# Apply the zodiac element mapping directly to the column\n",
    "executive['zodiac_element'] = executive['zodiac_sign'].map(zodiac_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zodiac_element color mapping\n",
    "# this dictionary maps each zodiac element to a specific color (hex code).\n",
    "# colors are chosen to represent traits commonly associated with each element.\n",
    "zodiac_element_colors = {\n",
    "    'Fire': '#FF4500',   # orange-red for Fire (passionate and energetic)\n",
    "    'Earth': '#8B4513',  # saddle brown for Earth (stable and grounded)\n",
    "    'Air': '#87CEEB',    # sky blue for Air (light and free-spirited)\n",
    "    'Water': '#4682B4'   # steel blue for Water (deep and emotional)\n",
    "}\n",
    "\n",
    "# Add a new column for zodiac element colors\n",
    "executive['zodiac_element_color'] = executive['zodiac_element'].map(zodiac_element_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ages at the start and end of terms\n",
    "\n",
    "def calculate_term_ages(row):\n",
    "    try:\n",
    "        return pd.Series({\n",
    "            'age_start': max(relativedelta(row['start_term'], row['birthdate']).years, 0),\n",
    "            'age_end': max(relativedelta(row['end_term'], row['birthdate']).years, 0)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return pd.Series({'age_start': None, 'age_end': None})\n",
    "\n",
    "# Apply the function and combine with DataFrame\n",
    "executive = pd.concat([executive, executive.apply(calculate_term_ages, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate term durations and format them\n",
    "\n",
    "# Calculate duration metrics (days, years, formatted strings) for each term\n",
    "def calculate_term_duration(row):\n",
    "    try:\n",
    "        # Calculate both timedelta and relativedelta for different metrics\n",
    "        delta = relativedelta(row['end_term'], row['start_term'])\n",
    "        days = (row['end_term'] - row['start_term']).days\n",
    "\n",
    "        # Calculate actual leap years in the term period\n",
    "        def is_leap_year(year):\n",
    "            return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "        \n",
    "        # Count actual leap years in the period\n",
    "        start_year = row['start_term'].year\n",
    "        end_year = row['end_term'].year\n",
    "        leap_years = sum(1 for year in range(start_year, end_year + 1) \n",
    "                        if is_leap_year(year))\n",
    "        \n",
    "        # Calculate exact years considering actual leap years\n",
    "        total_years = days / 365  # Start with regular years\n",
    "        if leap_years > 0:\n",
    "            # Adjust years calculation based on actual leap years\n",
    "            regular_days = days - leap_years\n",
    "            total_years = (regular_days / 365) + (leap_years / 366)\n",
    "        \n",
    "        return pd.Series({\n",
    "            'duration_days': days,\n",
    "            'total_duration_years': round(total_years, 2),\n",
    "            'duration_years_months': f\"{delta.years} year{'s' if delta.years != 1 else ''}, {delta.months} month{'s' if delta.months != 1 else ''}\",\n",
    "            'duration_years_months_days': f\"{delta.years} year{'s' if delta.years != 1 else ''}, {delta.months} month{'s' if delta.months != 1 else ''}, {delta.days} day{'s' if delta.days != 1 else ''}\"\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating duration: {e}\")\n",
    "        return pd.Series({k: None for k in ['duration_days', 'total_duration_years', 'duration_years_months', 'duration_years_months_days']})\n",
    "\n",
    "executive = pd.concat([executive, executive.apply(calculate_term_duration, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    'full_name', 'gender', 'birthdate', 'birthday', 'zodiac_sign', 'zodiac_color', 'zodiac_element', 'zodiac_element_color',\n",
    "    'type', 'party', 'start_term', 'end_term', 'age_start', 'age_end', 'duration_years_months_days', 'total_duration_years'\n",
    " ]\n",
    "\n",
    "# Create a new DataFrame with only the specified columns\n",
    "cleaned_executive = executive[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed DataFrame\n",
    "cleaned_executive.to_csv('cleaned_executive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "Carry out whatever EDA you need to for your project.  Because every project will be different we can't really give you much of a template at this point. But please make sure you describe the what and why in text here as well as providing interpretation of results and context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Analysis You Did - Give it a better title\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Analysis You Did - Give it a better title\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC AD NASEUM\n",
    "\n",
    "Some more words and stuff.  Remember notebooks work best if you interleave the code that generates a result with properly annotate figures and text that puts these results into context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discusison and Conclusion\n",
    "\n",
    "Wrap it all up here.  Somewhere between 3 and 10 paragraphs roughly.  A good time to refer back to your Background section and review how this work extended the previous stuff. \n",
    "\n",
    "\n",
    "# Team Contributions\n",
    "\n",
    "Speficy who did what.  This should be pretty granular, perhaps bullet points, no more than a few sentences per person."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
